{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM9/7K7acAZPtQMet3TkG1j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikosa01/TEAMNOLT/blob/main/group_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v6AX6CxhnGNC"
      },
      "outputs": [],
      "source": [
        "# Code to read csv file into colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import numpy as np \n",
        "from pathlib import Path\n",
        "import sys \n",
        "import tensorflow as tf\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot  as plt \n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "downloaded = drive.CreateFile({'id':'1c06v0ViaOvssxGV14zbggB72NcvFR6AE'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Group_Project_Data.zip') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "phLndkndofRh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_files = ['Train', 'Valid']\n",
        "for zip_file in zip_files:\n",
        "  with zipfile.ZipFile('Group_Project_Data.zip'.format(zip_file), 'r') as z: \n",
        "    z.extractall('.')\n",
        "    print('{} unzipped'.format(zip_file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0hT2VSIoico",
        "outputId": "651b5820-6280-40db-c364-d57439e33849"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train unzipped\n",
            "Valid unzipped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir =  '/content/Group_Project_Data/Train'\n",
        "val_dir =  '/content/Group_Project_Data/Valid'"
      ],
      "metadata": {
        "id": "3KJZpJ-0oqe_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)  # rescale pixel values to [0, 1]\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "fppaIWrUo6Y4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # resize images to 224x224 pixels\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # for multi-class classification\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoflGdH0pCFQ",
        "outputId": "6f658056-36ba-4f29-ca9f-9bc51f74e48f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "MdSAjwKKpN9M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SAwS4HFEpe1t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=10, validation_data=val_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MznaNbM9pfpp",
        "outputId": "2bba9546-7084-4f95-b1b5-9f05782aa780"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 16s 68ms/step - loss: 0.1672 - accuracy: 0.9657 - val_loss: 0.0197 - val_accuracy: 0.9965\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.0182 - val_accuracy: 0.9950\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 12s 63ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0087 - val_accuracy: 0.9965\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 12s 65ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 0.0110 - val_accuracy: 0.9950\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 12s 64ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 6.2799e-04 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1537 - val_accuracy: 0.9490\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 12s 62ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0266 - val_accuracy: 0.9930\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 11s 60ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0076 - val_accuracy: 0.9985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iXkCnwIKpjG2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}